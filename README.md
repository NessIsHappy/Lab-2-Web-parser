# Lab_2_Web_parser
Лабораторная работа №2. Извлечение и обработка данных из стороннего web-сервера с помощью Python-приложения
Цель работы: Получение навыков работы с протоколом HTTP: построение запросов к удаленному веб-серверу для получения содержимого веб-страницы. Получение навыков обработки и извлечения данных из HTML-страницы при помощи Python-библиотек. 
Задание на работу:
1.	Установить необходимые Python-библиотеки: requests.
2.	Перехватить экземпляр запроса к веб-сайту https://ruz.spbstu.ru. Для этого необходимо использовать утилиту burpsuite. Изучить заголовки запроса. 
3.	Включив фильтрацию результатов поиска (по номеру группы/по преподавателю), изучить то, как меняется URL запроса. Сделать выводы о параметрах в URL.
4.	Изучить HTTP-трафик, перехваченный при взаимодействии с целевым веб-сервером. Составить список конечных точек API, которые необходимы для извлечения расписания с заданным фильтром (по номеру группы/по преподавателю).
5.	Описать последовательность и логику запросов к API, которые необходимы для извлечения расписания.
6.	С помощью библиотеки requests выполнить GET-запрос к одной из конечных точек API. Проанализировать принцип передачи параметров в запросе, описать формат данных, содержащихся в ответе.
7.	В зависимости от варианта, используя библиотеку requests, извлечь из тела ответа расписание в формате: неделя (четная/нечетная), название предмета, дата, время, аудитория, преподаватель. Последовательность запросов должна воспроизводить изученную на предыдущих шагах логику работы веб-сайта.
Вариант 1 – фильтрация по номеру группы.
Вариант 2 – фильтрация по преподавателю.
В качестве результата работы программы в консоль выводится расписание занятий в зависимости от входных данных. 
Помимо текстового вывода необходимо представить расписание в виде графика. По оси абсцисс – день недели, по оси ординат – количество занятий. Для построения графика необходимо использовать библиотеку matplotlib.
8.	Написать отчет о проделанной работе.
9.	Ответить на контрольные вопросы:
1)	Какие виды HTTP-запросов существуют, для чего нужен каждый из них? Какие данные можно получить при отправке GET-запроса к web-ресурсу?
2)	Что такое DOM-объект, для чего он необходим? Какие библиотеки и функции были использованы при анализе HTML-страницы?
3)	По умолчанию в библиотеке requests включена проверка SSL-сертификатов. Что необходимо сделать, чтобы запросы к защищенным страницам работали корректно?
4)	Из каких частей состоит HTTP-запрос? Какие способы передачи параметров в запрос существуют?
